# üìà Stock Predictor API

API de previs√£o de pre√ßos de a√ß√µes usando redes neurais LSTM, desenvolvida para o **Tech Challenge Fase 4** da P√≥s-Tech FIAP.

## üéØ Objetivo

Desenvolver uma API que utiliza modelos LSTM para prever pre√ßos de a√ß√µes da bolsa de valores, com monitoramento via Prometheus e deploy na nuvem.

## üõ†Ô∏è Tecnologias

| Tecnologia | Uso |
|------------|-----|
| **FastAPI** | Framework web para a API REST |
| **PyTorch** | Deep Learning (modelo LSTM) |
| **SQLite** | Banco de dados local |
| **yfinance** | Coleta de dados de mercado |
| **Prometheus** | Monitoramento e m√©tricas |
| **Docker** | Containeriza√ß√£o |
| **Render** | Deploy na nuvem |


## üñ•Ô∏è Frontend (Dashboard)

A API agora acompanha uma interface web simples para facilitar o uso.

### Acesso

- **Dashboard**: [http://localhost:8000/](http://localhost:8000/)

### Funcionalidades do Frontend

1.  **Dashboard**: Vis√£o geral de modelos treinados e previs√µes recentes.
2.  **Ingest√£o**: Formul√°rio para baixar dados hist√≥ricos (com suporte a datas).
3.  **Treinamento**: Interface para treinar novos modelos (s√≠ncrono ou ass√≠ncrono).
4.  **Predi√ß√£o**:
    *   **Padr√£o**: Prever usando a√ß√µes cadastradas.
    *   **Custom**: Prever usando dados hist√≥ricos colados manualmente.
5.  **Hist√≥rico**: Visualizar todas as previs√µes realizadas.

## üìÅ Estrutura do Projeto

```
stock-predictor-api/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI app principal
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configura√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ database.py          # Conex√£o SQLite
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lstm.py          # Modelo LSTM
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py       # Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_service.py  # Processamento de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_service.py # Treinamento
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict_service.py
‚îÇ   ‚îî‚îÄ‚îÄ routers/
‚îÇ       ‚îú‚îÄ‚îÄ training.py      # Endpoints de treino
‚îÇ       ‚îú‚îÄ‚îÄ inference.py     # Endpoints de previs√£o
‚îÇ       ‚îú‚îÄ‚îÄ monitoring.py    # M√©tricas Prometheus
‚îÇ       ‚îî‚îÄ‚îÄ frontend.py      # [NEW] Rotas do Frontend
‚îÇ   ‚îú‚îÄ‚îÄ templates/           # [NEW] Arquivos HTML (Jinja2)
‚îÇ   ‚îî‚îÄ‚îÄ static/              # [NEW] Arquivos est√°ticos (CSS/JS)
‚îú‚îÄ‚îÄ data/models/             # Modelos treinados (.pt)
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ ingest.py                # Script de ingest√£o
‚îú‚îÄ‚îÄ train_test.py            # Script de teste
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ prometheus.yml
‚îú‚îÄ‚îÄ render.yaml
‚îî‚îÄ‚îÄ requirements.txt
```

## üöÄ Quick Start

### Pr√©-requisitos

- Python 3.11+
- Anaconda (recomendado) ou pip

### 1. Ativar Ambiente

```powershell
# Windows com Anaconda
& C:\Users\junio\anaconda3\shell\condabin\conda-hook.ps1
conda activate base
cd c:\Users\junio\tech-challenge4-lstm-stock-predictor-api
```

### 2. Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

### 3. Ingerir Dados

```bash
# Baixar dados de PETR4.SA e AAPL (2 anos)
python ingest.py PETR4.SA AAPL

# Ou com per√≠odo customizado
python ingest.py VALE3.SA --period 5y
```

### 4. Treinar e Testar

```bash
# Treinar modelo e fazer previs√£o
python train_test.py PETR4.SA --epochs 50
```

### 5. Iniciar a API

```bash
python -m uvicorn app.main:app --reload --host 127.0.0.1 --port 8000
```

### 6. Acessar a API

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health
- **M√©tricas**: http://localhost:8000/metrics

## üì° Endpoints da API

| M√©todo | Endpoint | Descri√ß√£o |
|--------|----------|-----------|
| GET | `/health` | Health check |
| GET | `/metrics` | M√©tricas Prometheus |
| POST | `/api/v1/ingest/{ticker}` | Ingerir dados (start_date, end_date) |
| POST | `/api/v1/train/{ticker}` | Treinar modelo |
| POST | `/api/v1/predict/{ticker}` | Previs√£o por ticker (dados do banco) |
| POST | `/api/v1/predict/custom` | **Previs√£o com dados do usu√°rio** |
| GET | `/api/v1/models` | Listar modelos |
| GET | `/api/v1/predictions/history` | Hist√≥rico |

### Exemplos de Uso

#### Ingerir Dados (com datas espec√≠ficas)
```bash
# Usando datas espec√≠ficas (formato YYYY-MM-DD)
curl -X POST "http://localhost:8000/api/v1/ingest/PETR4.SA?start_date=2018-01-01&end_date=2024-07-20"

# Sem datas (usa √∫ltimos 2 anos por padr√£o)
curl -X POST "http://localhost:8000/api/v1/ingest/PETR4.SA"
```

#### Treinar Modelo
```bash
curl -X POST "http://localhost:8000/api/v1/train/PETR4.SA" \
  -H "Content-Type: application/json" \
  -d '{"epochs": 50, "batch_size": 32}'
```

#### Fazer Previs√£o (por ticker)
```bash
curl -X POST "http://localhost:8000/api/v1/predict/PETR4.SA" \
  -H "Content-Type: application/json" \
  -d '{"days": 1}'
```

#### Fazer Previs√£o (com dados do usu√°rio)

Este endpoint atende ao requisito do Tech Challenge:
> "A API deve permitir que o usu√°rio forne√ßa dados hist√≥ricos de pre√ßos e receba previs√µes"

```bash
curl -X POST "http://localhost:8000/api/v1/predict/custom" \
  -H "Content-Type: application/json" \
  -d '{
    "historical_prices": [30.5, 30.7, 30.9, 31.1, 31.3, 31.5, 31.7, 31.9, 32.1, 32.3,
                          32.5, 32.7, 32.9, 33.1, 33.3, 33.5, 33.7, 33.9, 34.1, 34.3,
                          34.5, 34.7, 34.9, 35.1, 35.3, 35.5, 35.7, 35.9, 36.1, 36.3,
                          36.5, 36.7, 36.9, 37.1, 37.3, 37.5, 37.7, 37.9, 38.1, 38.3,
                          38.5, 38.7, 38.9, 39.1, 39.3, 39.5, 39.7, 39.9, 40.1, 40.3,
                          40.5, 40.7, 40.9, 41.1, 41.3, 41.5, 41.7, 41.9, 42.1, 42.3],
    "days": 3,
    "model_ticker": "PETR4.SA"
  }'
```

**Par√¢metros:**
- `historical_prices`: Lista de pre√ßos hist√≥ricos (m√≠nimo 60 valores)
- `days`: N√∫mero de dias para prever (1-30)
- `model_ticker`: Ticker do modelo a ser usado

## üß† Modelo LSTM

### Arquitetura

```
Input (batch, 60, n_features)
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  nn.LSTM                   ‚îÇ
‚îÇ  ‚Ä¢ hidden_size: 50         ‚îÇ
‚îÇ  ‚Ä¢ num_layers: 2           ‚îÇ
‚îÇ  ‚Ä¢ dropout: 0.2            ‚îÇ
‚îÇ  ‚Ä¢ bias: True              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
    √öltimo timestep
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  nn.Dropout(0.2)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  nn.Linear(50, 1)          ‚îÇ
‚îÇ  ‚Ä¢ bias: True              ‚îÇ
‚îÇ  ‚Ä¢ ativa√ß√£o: Nenhuma       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
Output (batch, 1) ‚Üí pre√ßo previsto
```

### Fun√ß√µes de Ativa√ß√£o (Internas da LSTM)

A LSTM usa **4 gates** com ativa√ß√µes espec√≠ficas (implementa√ß√£o PyTorch):

| Gate | Ativa√ß√£o | F√≥rmula | Prop√≥sito |
|------|----------|---------|-----------|
| **Forget Gate** | Sigmoid | `œÉ(Wf¬∑[ht-1, xt] + bf)` | Decide o que esquecer |
| **Input Gate** | Sigmoid | `œÉ(Wi¬∑[ht-1, xt] + bi)` | Decide o que atualizar |
| **Candidate** | Tanh | `tanh(Wc¬∑[ht-1, xt] + bc)` | Cria novos candidatos |
| **Output Gate** | Sigmoid | `œÉ(Wo¬∑[ht-1, xt] + bo)` | Decide a sa√≠da |

- **Sigmoid (0-1)**: Atua como "porta" - 0 = bloqueia, 1 = permite
- **Tanh (-1 a 1)**: Permite ajustes bidirecionais

### Par√¢metros do Modelo

| Par√¢metro | Valor | Descri√ß√£o |
|-----------|-------|-----------|
| `input_size` | 1-4 | Features por timestep (close, volume, rsi, ema) |
| `hidden_size` | 50 | Neur√¥nios LSTM por camada |
| `num_layers` | 2 | Camadas empilhadas |
| `dropout` | 0.2 | 20% regulariza√ß√£o |
| `output_size` | 1 | Pre√ßo previsto |
| `window_size` | 60 | Dias de input |
| `bias` | True | Offset aprend√≠vel em cada gate |

### Loss e Otimizador

| Componente | Implementa√ß√£o | Motivo |
|------------|---------------|--------|
| **Loss** | `MSELoss` | Regress√£o - penaliza erros quadr√°ticos |
| **Otimizador** | `Adam` | Converge r√°pido, adapta LR por par√¢metro |
| **Learning Rate** | 0.001 | Padr√£o conservador |

### Pr√©-processamento

1. **Scaling**: MinMaxScaler (normaliza√ß√£o 0-1)
2. **Windowing**: Janela deslizante de 60 dias
3. **Split**: 80% treino, 20% teste (temporal)

#### ‚ö†Ô∏è Preven√ß√£o de Data Leakage

O pipeline de dados foi cuidadosamente projetado para **evitar data leakage** na normaliza√ß√£o:

```
‚ùå Errado: Normalizar ‚Üí Dividir (scaler "v√™" dados de teste)
‚úÖ Correto: Dividir ‚Üí Normalizar treino ‚Üí Aplicar no teste
```

**Implementa√ß√£o em `data_service.py`:**

1. **Split primeiro**: Dados brutos s√£o divididos em 80/20 **antes** de qualquer processamento
2. **Fit apenas no treino**: `scaler.fit()` √© chamado **apenas** nos dados de treino
3. **Transform no teste**: Dados de teste usam `scaler.transform()` (n√£o refit)
4. **Contexto preservado**: √öltimos 60 dias do treino s√£o usados como contexto inicial para sequ√™ncias de teste

Isso garante que o modelo nunca tenha acesso a informa√ß√µes do futuro durante o treinamento.

### M√©tricas de Avalia√ß√£o

- **RMSE**: Root Mean Squared Error (em R$)
- **MAE**: Mean Absolute Error (em R$)
- **MAPE**: Mean Absolute Percentage Error (%)

## üê≥ Docker

### Build e Run

```bash
# Build
docker build -t stock-predictor-api .

# Run
docker run -p 8000:8000 stock-predictor-api
```

### Docker Compose (API + Prometheus + Grafana)

```bash
docker compose up -d
```

Servi√ßos:
- API: http://localhost:8000
- Swagger UI: http://localhost:8000/docs
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000 (admin/admin)

### Ver Logs dos Containers

```powershell
# Logs da API (tempo real)
docker logs stock-predictor-api -f

# Logs do Prometheus
docker logs stock-predictor-prometheus -f

# Logs do Grafana
docker logs stock-predictor-grafana -f

# Logs de TODOS os servi√ßos
docker compose logs -f

# √öltimas 50 linhas
docker compose logs --tail 50
```

> **Dica**: Use `Ctrl+C` para sair do modo de logs em tempo real.

### Comandos √öteis Docker

| Comando | Descri√ß√£o |
|---------|-----------|
| `docker compose up -d` | Iniciar todos os servi√ßos |
| `docker compose down` | Parar todos os servi√ßos |
| `docker compose restart` | Reiniciar servi√ßos |
| `docker compose logs -f` | Ver logs em tempo real |
| `docker ps` | Listar containers rodando |
| `docker compose up -d --build` | Rebuild e reiniciar |

### Executar Endpoints via Docker

Com os containers rodando (`docker compose up -d`), use o Swagger UI ou os comandos abaixo:

**Via Swagger (Recomendado):**
1. Acesse http://localhost:8000/docs
2. Clique no endpoint desejado
3. Clique em "Try it out"
4. Preencha os par√¢metros
5. Clique em "Execute"

**Via PowerShell:**
```powershell
# Verificar se API est√° rodando
Invoke-RestMethod -Uri "http://localhost:8000/health"

# Ingerir dados
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/ingest/AAPL?period=1y" -Method Post

# Treinar modelo
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/train/AAPL" -Method Post -ContentType "application/json" -Body '{"epochs": 5}'

# Fazer previs√£o
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/predict/AAPL" -Method Post -ContentType "application/json" -Body '{"days": 1}'

# Listar modelos
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/models"
```


## ‚òÅÔ∏è Deploy no Render

1. Fa√ßa push do projeto para GitHub
2. Acesse https://render.com
3. New ‚Üí Blueprint
4. Conecte o reposit√≥rio
5. Render detectar√° o `render.yaml` automaticamente
6. Clique em Apply

> **Nota**: Plano free tem 512MB RAM e entra em sleep ap√≥s 15min.

## üìä Monitoramento

### M√©tricas Prometheus Dispon√≠veis

```
stock_predictor_requests_total        # Total de requisi√ß√µes
stock_predictor_predictions_total     # Total de previs√µes realizadas
stock_predictor_trainings_total       # Total de treinamentos
stock_predictor_request_latency_seconds   # Lat√™ncia das requisi√ß√µes
stock_predictor_training_duration_seconds # Dura√ß√£o dos treinamentos
stock_predictor_models_count          # N√∫mero de modelos treinados
stock_predictor_last_prediction_price # √öltimo pre√ßo previsto
```

### Configurar Prometheus

1. Acesse http://localhost:9090
2. V√° em **Status ‚Üí Targets** para verificar se os targets est√£o UP
3. Na aba **Graph**, digite uma query:

**Queries que sempre funcionam:**
```promql
# Informa√ß√µes do Python
python_info

# Mem√≥ria do processo
process_resident_memory_bytes

# CPU utilizada
process_cpu_seconds_total

# Garbage Collector
python_gc_collections_total
```

**Queries personalizadas (ap√≥s usar a API):**
```promql
# Total de previs√µes
stock_predictor_predictions_total

# √öltimo pre√ßo previsto por ticker
stock_predictor_last_prediction_price

# Total de treinamentos
stock_predictor_trainings_total

# Dura√ß√£o dos treinamentos
stock_predictor_training_duration_seconds_sum
```

> **Nota**: As m√©tricas `stock_predictor_*` s√≥ aparecem ap√≥s a primeira utiliza√ß√£o da API (previs√£o, treino, etc.)

### Gerar M√©tricas via Aplica√ß√£o

Para que as m√©tricas apare√ßam no Prometheus, voc√™ precisa **usar a API**. Siga estes passos:

**Op√ß√£o 1: Via Swagger UI (Interface Gr√°fica)**

1. Acesse http://localhost:8000/docs
2. **Ingerir dados** (necess√°rio antes de treinar):
   - Clique em `POST /api/v1/ingest/{ticker}`
   - Clique em "Try it out"
   - Digite o ticker: `AAPL` (ou `PETR4.SA`)
   - Clique em "Execute"
3. **Treinar modelo**:
   - Clique em `POST /api/v1/train/{ticker}`
   - Clique em "Try it out"
   - Digite o ticker: `AAPL`
   - No body, use: `{"epochs": 5}`
   - Clique em "Execute"
4. **Fazer previs√£o**:
   - Clique em `POST /api/v1/predict/{ticker}`
   - Clique em "Try it out"
   - Digite o ticker: `AAPL`
   - No body, use: `{"days": 1}`
   - Clique em "Execute"

**Op√ß√£o 2: Via Linha de Comando (PowerShell)**

```powershell
# 1. Ingerir dados (baixar 1 ano de hist√≥rico)
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/ingest/AAPL?period=1y" -Method Post

# 2. Treinar modelo (5 epochs para teste r√°pido)
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/train/AAPL" -Method Post -ContentType "application/json" -Body '{"epochs": 5}'

# 3. Fazer previs√£o
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/predict/AAPL" -Method Post -ContentType "application/json" -Body '{"days": 1}'
```

**Op√ß√£o 3: Via cURL (Linux/Mac)**

```bash
# 1. Ingerir dados
curl -X POST "http://localhost:8000/api/v1/ingest/AAPL?period=1y"

# 2. Treinar modelo
curl -X POST "http://localhost:8000/api/v1/train/AAPL" \
  -H "Content-Type: application/json" \
  -d '{"epochs": 5}'

# 3. Fazer previs√£o
curl -X POST "http://localhost:8000/api/v1/predict/AAPL" \
  -H "Content-Type: application/json" \
  -d '{"days": 1}'
```

Ap√≥s executar esses comandos, acesse http://localhost:9090 e verifique as m√©tricas!

### Configurar Grafana

1. Acesse http://localhost:3000
2. Login: `admin` / `admin`

**Adicionar Data Source:**
1. Clique em ‚öôÔ∏è ‚Üí **Data Sources**
2. Clique em **Add data source**
3. Selecione **Prometheus**
4. Em URL digite: `http://prometheus:9090`
5. Clique em **Save & Test**

**Criar Dashboard:**
1. Clique em **+** ‚Üí **Dashboard**
2. Clique em **Add visualization**
3. Selecione **Prometheus** como data source
4. Digite a query (ex: `process_resident_memory_bytes`)
5. Clique em **Apply**

**Pain√©is sugeridos:**
| M√©trica | Tipo | Descri√ß√£o |
|---------|------|-----------|
| `process_resident_memory_bytes` | Gauge | Mem√≥ria RAM usada |
| `process_cpu_seconds_total` | Counter | CPU acumulada |
| `stock_predictor_predictions_total` | Counter | Previs√µes realizadas |
| `stock_predictor_last_prediction_price` | Gauge | √öltimo pre√ßo previsto |

## üß™ Testes

```bash
# Executar testes
pytest tests/ -v

# Com cobertura
pytest tests/ --cov=app --cov-report=html
```

## üìù Licen√ßa

MIT License

## üë®‚Äçüíª Autor

**Tech Challenge Fase 4** - P√≥s-Tech FIAP Machine Learning Engineering
